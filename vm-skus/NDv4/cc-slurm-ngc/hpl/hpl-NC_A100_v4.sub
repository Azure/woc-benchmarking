#!/bin/bash
#SBATCH -t 00:20:00
#SBATCH --ntasks-per-node=4
#SBATCH --mem=0
#SBATCH --gpus-per-node=4
#SBATCH -o logs/%x_%j.log
#SBATCH --exclusive

#export SLURM_WHOLE=1
env | grep -i slurm
env | grep -i log

CONT='nvcr.io/nvidia/hpc-benchmarks:21.4-hpl'
MOUNT='/shared/data/azure/benchmarking/NDv4/cc-slurm-ngc/hpl/dats/hpl-NC_A100_v4-${SLURM_JOB_NUM_NODES}N.dat:/workspace/hpl-linux-x86_64/sample-dat/HPL-${SLURM_JOB_NUM_NODES}N.dat'
echo "Running on hosts: $(echo $(scontrol show hostname))"

export OMPI_MCA_pml=ucx
export OMPI_MCA_btl=^openib,smcuda
export UCX_NET_DEVICES=eth0

#CPU_AFFINITY="24-35:36-47:0-11:12-23:72-83:84-95:48-59:60-71"
#GPU_AFFINITY="0:1:2:3:4:5:6:7"
#MEM_AFFINITY="1:1:0:0:3:3:2:2"
DAT="/workspace/hpl-linux-x86_64/sample-dat/HPL-${SLURM_JOB_NUM_NODES}N.dat"

#CMD="hpl.sh --cpu-affinity ${CPU_AFFINITY} --cpu-cores-per-rank 12 --gpu-affinity ${GPU_AFFINITY} --mem-affinity ${MEM_AFFINITY} --ucx-affinity ${UCX_AFFINITY} --dat ${DAT}"
CMD="hpl.sh --cpu-cores-per-rank 24 --dat ${DAT}"

srun \
   --ntasks-per-node=1 \
   --ntasks=$SLURM_JOB_NUM_NODES \
   --whole --gpus-per-node=4 \
   --container-name=hpl \
   --container-image="${CONT}" \
   --container-mounts="${MOUNT}" \
   bash -c "ls -l /workspace/hpl-linux-x86_64/sample-dat;ls -l /workspace/hpl-linux-x86_64/sample-dat/HPL-${SLURM_JOB_NUM_NODES}N.dat "

srun \
    --whole \
    --gpus-per-node=4 \
    --container-name=hpl \
    --container-mounts="${MOUNT}" \
    bash -c "${CMD}"
